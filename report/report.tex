\documentclass[12pt,a4paper]{article}

\usepackage{titling}
\usepackage{float}
\usepackage{subcaption}
\usepackage{longtable}

\setlength{\droptitle}{-10em}
\usepackage[table]{xcolor}

% New language font setup
\usepackage{fontspec}
\usepackage{polyglossia}
\usepackage[final]{microtype}
\sloppy

\setmainfont{Libertinus Serif}
\setmonofont{Libertinus Mono}
\setsansfont{Libertinus Sans}

\setdefaultlanguage{greek}
\setotherlanguages{english}

\usepackage{pgfplotstable}
\usepackage{booktabs}
\usepackage{etoolbox}
\pgfplotsset{compat=newest}

\usepackage{hyperref}
\usepackage{xurl}

\usepackage{listings}

\lstdefinestyle{cppstyle}{
    language=C++,
    keywordstyle=\color{blue}\bfseries,
    commentstyle=\color{gray}\itshape,
    stringstyle=\color{orange},
    backgroundcolor=\color{white},
    breaklines=true,
    frame=single,
    showstringspaces=false
}

\lstdefinestyle{pythonstyle}{
    language=Python,
    keywordstyle=\color{purple}\bfseries,
    commentstyle=\color{gray}\itshape,
    stringstyle=\color{teal},
    backgroundcolor=\color{white},
    breaklines=true,
    frame=single,
    showstringspaces=false,
    tabsize=4
}

\usepackage{graphicx}
\graphicspath{{images/}}

\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{svg}
\svgpath{{./images}} 

\usepackage[backend=biber, style=ieee]{biblatex}
\addbibresource{references.bib}

% Remove page numbering
\pagestyle{empty}

\setcounter{tocdepth}{3}

\begin{document}

\begin{titlepage}

\noindent
\begin{minipage}[t]{0.25\textwidth}
    \vspace{0pt}
    \includesvg[width=\textwidth]{emp_logo.svg}
\end{minipage}%
\hfill
\begin{minipage}[t]{0.70\textwidth}
    \vspace{0pt}
    \raggedleft
    {\Large Εθνικό Μετσόβιο Πολυτεχνείο}\\[0.3em]
    {\large Σχολή Ηλεκτρολόγων Μηχανικών και Μηχανικών Υπολογιστών}\\
    {Προηγμένα Θέματα Τεχνητής Νοημοσύνης}\\
    {9ο εξάμηνο}
\end{minipage}

\vspace{3cm}

\begin{center}
    {\huge \textbf{Benchmarking Monocular Depth Estimation Models}}\\[1cm]
    {\large Υπεύθυνοι εργασίας:}\\
    {\large Α. Βουλόδημος}\\
    {\large Β. Καραμπίνης}\\
    {\large Η. Μήτσουρας}
\end{center}

\vfill

\begin{center}
    {\large Νικόλας Σπυρόπουλος, ΑΜ: 03121202}
\end{center}

\end{titlepage}

\tableofcontents
\newpage

\section{Περίληψη}
Η κατανόηση της τρισδιάστατης δομής ενός σκηνικού αποτελεί θεμελιώδη στόχο του τομέα της Όρασης Υπολογιστή (Computer Vision), με εφαρμογές στην αυτόνομη οδήγηση, τη ρομποτική πλοήγηση, την επαυξημένη πραγματικότητα (AR), την τρισδιάστατη ανακατασκευή και την ανάλυση σκηνών. Ένα από τα πιο σημαντικά προβλήματα που συνδέονται με αυτή την κατανόηση είναι η \textbf{εκτίμηση βάθους (Depth Estimation)}, δηλαδή ο υπολογισμός της απόστασης κάθε σημείου της εικόνας (pixel) από την κάμερα.

Τα τελευταία χρόνια, έχουν αναπτυχθεί μοντέλα εκτίμησης βάθους που μπορούν να παράγουν ακριβείς χάρτες βάθους ακόμη και από μία μόνο RGB εικόνα. Η συγκεκριμένη εφαρμογή ονομάζεται \textbf{Monocular Depth Estimation} καθώς δεν χρειάζεται δεδομένα από πολλούς αισθητήρες ή πολλές κάμερες, παρά μόνο μια εικόνα. Στο πλαίσιο αυτής της εργασίας, εξετάζονται τέσσερα σύγχρονα μοντέλα —\textbf{MiDaS}, \textbf{ZoeDepth}, \textbf{Depth-Anything-V2} και \textbf{Marigold}— τα οποία αντιπροσωπεύουν διαφορετικές αρχιτεκτονικές, τεχνικές μάθησης και επίπεδα ικανότητας στη γενίκευση μεταξύ τομέων (\textbf{domain generalization}). Αφού πρώτα, αναλυθούν οι αρχιτεκτονικές και οι ιδιαιτερότητες τους, θα γίνει σύγκριση της ακρίβειας των μοντέλων χρησιμοποιώντας ευρέως διαδεδομένα σύνολα δεδομένων(datasets).

Πριν παρουσιαστούν τα μοντέλα, είναι απαραίτητο να δοθούν οι βασικές έννοιες της εκτίμησης βάθους και τα είδη της, καθώς και το πρόβλημα της γενίκευσης τομέα, το οποίο αποτελεί κρίσιμο σημείο για την επιτυχία των μοντέλων Monocular Depth Estimation. %\cite{zhang2025surveymonocularmetricdepth}

\section{Εκτίμηση Βάθους (Depth Estimation)}
Η εκτίμηση βάθους στοχεύει στην εξαγωγή ενός \textbf{χάρτη βάθους (depth map)}, στον οποίο για κάθε pixel αντιστοιχεί μια εκτίμηση της απόστασής του από την κάμερα. Παραδοσιακές προσεγγίσεις στηρίζονται σε στερεοσκοπικά συστήματα ή σε αισθητήρες ενεργού βάθους (όπως LiDAR ή ToF). Ωστόσο, η δυνατότητα πρόβλεψης βάθους από μόνο μια οπτική μιας εικόνας (monocular depth estimation) είναι ιδιαίτερα ελκυστική λόγω του χαμηλού κόστους, της ευκολίας ενσωμάτωσης και της ευρείας διαθεσιμότητας συστημάτων που διαθέτουν μόνο μία κάμερα.

Η εκτίμηση βάθους από μία μόνο εικόνα αποτελεί μη-σαφώς ορισμένο πρόβλημα (\textbf{ill-posed}), καθώς άπειρες τρισδιάστατες σκηνές μπορούν να προβάλουν την ίδια δισδιάστατη εικόνα. Γι’ αυτό, τα σύγχρονα μοντέλα βασίζονται σε μεγάλο βαθμό στη μάθηση στατιστικών και γεωμετρικών προτύπων από δεδομένα \cite{zhang2025surveymonocularmetricdepth}.

Η εκτίμηση βάθους διακρίνεται σε δύο βασικές υποκατηγορίες\footnote{\url{https://huggingface.co/docs/transformers/tasks/monocular_depth_estimation}}: \textbf{Απόλυτη (Absolute/Metric)} και \textbf{Σχετική (Relative)} εκτίμηση βάθους.

\subsection{Απόλυτη Εκτίμηση Βάθους (Absolute Depth Estimation)}
Η απόλυτη εκτίμηση βάθους αναφέρεται στην πρόβλεψη της πραγματικής απόστασης κάθε σημείου της σκηνής από την κάμερα, σε φυσικές μονάδες όπως μέτρα. Σε αυτή την περίπτωση, το μοντέλο πρέπει να εκτιμήσει όχι μόνο το σχήμα και τη δομή της σκηνής, αλλά και την κλίμακα της, ώστε ο χάρτης βάθους να ανταποκρίνεται ακριβώς στην πραγματικότητα. Η εκπαίδευση τέτοιων μοντέλων απαιτεί δεδομένα με μετρικές ετικέτες, συνήθως από αισθητήρες όπως LiDAR, structured light ή Time-of-Flight. Εξαιτίας αυτής της εξάρτησης από συγκεκριμένα συστήματα λήψης για ακριβείς μετρήσεις, η απόλυτη εκτίμηση βάθους είναι ευαίσθητη σε αλλαγές τομέα, όπως διαφορετικές κάμερες, φωτιστικές συνθήκες ή τύπους σκηνών. Παρ' όλα αυτά, αποτελεί αναντικατάστατη προσέγγιση σε εφαρμογές όπου η πραγματική απόσταση είναι κρίσιμη, όπως η αυτόνομη οδήγηση, η ρομποτική πλοήγηση και η τρισδιάστατη χαρτογράφηση.

\subsection{Σχετική Εκτίμηση Βάθους (Relative Depth Estimation)}
Η σχετική εκτίμηση βάθους επικεντρώνεται στην πρόβλεψη της δομής και της τοπολογίας της σκηνής, χωρίς να επιδιώκει να εκφράσει τις αποστάσεις σε πραγματικές μονάδες. Ο χάρτης βάθους που παράγει ένα τέτοιο μοντέλο είναι σε κλίμακα η οποία δεν έχει κάποια φυσική σημασία, αποτυπώνοντας όμως με συνέπεια το ποια σημεία βρίσκονται πιο κοντά ή πιο μακριά από την κάμερα. Επειδή δεν απαιτείται μετρικό ground truth, η σχετική εκτίμηση βάθους μπορεί να εκπαιδευτεί σε πολύ μεγάλα, ετερογενή σύνολα δεδομένων, συχνά προερχόμενα από διαφορετικές πηγές ή με ποικιλία σκηνών. Αυτό καθιστά τη μέθοδο ιδιαίτερα ανθεκτική σε αλλαγές τομέα, με αποτέλεσμα να επιτυγχάνει καλύτερη γενίκευση σε νέες συνθήκες, διαφορετικούς τύπους σκηνών ή διαφορετικούς αισθητήρες. Για τον λόγο αυτό, πολλά σύγχρονα μοντέλα που δίνουν έμφαση στην ευρεία γενίκευση υιοθετούν τη σχετική εκτίμηση βάθους, ιδιαίτερα όταν η ακριβής κλίμακα δεν αποτελεί προϋπόθεση για την εκάστοτε εφαρμογή.

\section{Γενίκευση Τομέα (Domain Generalization)}
Η γενίκευση τομέα αποτελεί ένα από τα βασικά ζητήματα στη εκτίμηση βάθους από μία εικόνα και αναφέρεται στην ικανότητα ενός μοντέλου να διατηρεί υψηλή απόδοση όταν εφαρμόζεται σε δεδομένα που διαφέρουν από αυτά στα οποία εκπαιδεύτηκε. Ένα μοντέλο που δεν γενικεύει καλά μπορεί να λειτουργεί άριστα σε ένα συγκεκριμένο σύνολο δεδομένων, αλλά να παρουσιάζει σημαντική πτώση στην απόδοση όταν αντιμετωπίζει διαφορετικές σκηνές, συνθήκες φωτισμού ή κάμερες.

Η αντιμετώπιση του προβλήματος της γενίκευσης τομέα απαιτεί ειδικές στρατηγικές, όπως η εκπαίδευση σε ποικιλόμορφα και πολυδιάστατα datasets, η χρήση τεχνικών κανονικοποίησης και scale-invariant loss functions \cite{eigen2014depthmappredictionsingle}, καθώς και η αξιοποίηση μεγάλων συνόλων συνθετικών \cite{Yao_2024} και πραγματικών δεδομένων. Όλα τα μοντέλα που εξετάζονται στην εργασία —MiDaS, ZoeDepth, Depth-Anything-V2 και Marigold— αντιμετωπίζουν το ζήτημα της γενίκευσης με διαφορετικούς τρόπους, στοχεύοντας στην επίτευξη αξιόπιστης απόδοσης σε ποικίλες συνθήκες και σκηνές, ανεξαρτήτως των δεδομένων εκπαίδευσης.

\section{MiDaS (Mixing Datasets for Zero-shot Cross-dataset Transfer)}
Το MiDaS αντιπροσωπεύει μια κομβική εξέλιξη στην εκτίμηση βάθους από μία μόνο εικόνα, καθώς αντιμετωπίζει συστηματικά το κρίσιμο πρόβλημα της γενίκευσης τομέα. Η επιτυχία του μοντέλου έγκειται στην ανάπτυξη μεθοδολογιών για την αποτελεσματική \textbf{σύνθεση ετερογενών συνόλων δεδομένων (mixing datasets)}, ακόμη και αν οι αρχικές τους ετικέτες βάθους είναι ασύμβατες. Οι πρώτες δύο εκδόσεις του MiDaS χρησιμοποιούσαν συνελικτικά νευρωνικά δίκτυα (Convolutional Neural Networks - CNNS) \cite{ranftl2020robustmonoculardepthestimation}, ενώ η τρίτη και τελευταία έκδοση υιοθετεί διαφορετικές αρχιτεκτονικές Vision Transfer (ViT) \cite{ranftl2021visiontransformersdenseprediction} ακολουθώντας τις εξελίξεις στο πεδίο της όρασης υπολογιστή. 

\subsection{Αρχιτεκτονική}
Η αρχιτεκτονική του MiDaS εξελίχθηκε σε δύο κύριες φάσεις, διατηρώντας πάντα τη βασική δομή \textbf{Κωδικοποιητή-Αποκωδικοποιητή (Encoder-Decoder)}.

\subsubsection{MiDaS v1 \& v2 (CNN-based)}
Οι αρχικές εκδόσεις του MiDaS βασίστηκαν στα \textbf{Συνελικτικά Νευρωνικά Δίκτυα (CNNs)}, τα οποία ήταν η κυρίαρχη τεχνολογία για την Όραση Υπολογιστή την εποχή της πρώτης δημοσίευσης \cite{ranftl2020robustmonoculardepthestimation}. 
\begin{itemize}
    \item \textbf{Κωδικοποιητής (Encoder)}: Χρησιμοποιήθηκε ένα δίκτυο υψηλής χωρητικότητας τύπου \textbf{ResNeXt-101-WSL (Weakly-Supervised Learning)}. Η επιλογή ενός τόσο βαθιού δικτύου και η προ-εκπαίδευση σε μαζικά, αδύναμα επιβλεπόμενα δεδομένα (WSL) επέτρεψε στον κωδικοποιητή να μάθει εξαιρετικά ισχυρές και γενικεύσιμες αναπαραστάσεις χαρακτηριστικών (Transfer Learning), απαραίτητες για την επιτυχία του zero-shot transfer. Στην αρχική δημοσίευση αναφέρεται επίσης ότι και με χρήση ενός μικρότερου κωδικοποιητή, όπως το \textbf{ResNet-50}, το μοντέλο κατάφερε να επιτύχει καλύτερη απόδοση από τα τότε state-of-the-art μοντέλα.
    \item \textbf{Αποκωδικοποιητής / Κεφαλή προβλέψεων (Decoder / Prediction Head)}: Ο αποκωδικοποιητής ήταν υπεύθυνος για την ανασύνθεση του χάρτη βάθους από τα αφηρημένα χαρακτηριστικά του κωδικοποιητή. Χρησιμοποιούσε τεχνικές \textbf{multi-scale feature fusion}\footnote{\url{https://medium.com/@nbeel.original/getting-started-with- depth-estimation-using-midas-and-python-d0119bfe1159}} μέσω συνδέσεων παράκαμψης (Skip Connections), για να συνδυάσει λεπτομερή χωρικά χαρακτηριστικά (από ρηχά στρώματα) με εννοιολογικές πληροφορίες (από βαθιά στρώματα), επαναφέροντας την ανάλυση στην αρχική διάσταση της εικόνας μέσω \textbf{ανοδικής δειγματοληψίας (Upsampling)}.

\end{itemize}

\subsubsection{MiDaS v3.0 \& v3.1 / DPT (Transformer-Based)}
Οι νεότερες εκδόσεις του MiDaS (συχνά αναφερόμενες ως \textbf{DPT - Dense Prediction Transformer}) διατήρησαν τη μεθοδολογία εκπαίδευσης, αλλά αντικατέστησαν τον CNN κωδικοποιητή με ένα \textbf{Vision Transformer (ViT)} \cite{ranftl2021visiontransformersdenseprediction}.

\begin{itemize}
    \item \textbf{Κωδικοποιητής (Encoder)}: Υιοθετήθηκαν διάφοροι ViT backbones, όπως ViT, BEIT, Swin και SwinV2. Η επιτυχία τους οφείλεται στην ικανότητά τους να μοντελοποιούν μακροχρόνιες εξαρτήσεις (long-range dependencies) σε όλη την εικόνα, καταγράφοντας αποτελεσματικότερα την ολική γεωμετρία (global structure) της σκηνής. Αυτό βελτιώνει περαιτέρω τη γενίκευση σε σκηνές με άγνωστη δομή.
    \item \textbf{Αποκωδικοποιητής (Decoder)}: Η αρχιτεκτονική του αποκωδικοποιητή προσαρμόστηκε για να λαμβάνει ως είσοδο τα "\textbf{tokens}" (τα διακριτά τμήματα πληροφορίας) από τα διάφορα στάδια του Transformer. Στην συνέχεια "συναρμολογεί" εκ νέου (\textbf{reassemble}) αυτά τα tokens σε αναπαραστάσεις εικόνας πολλαπλών αναλύσεων, τις οποίες επεξεργάζεται για να παραχθεί ο τελικός πυκνός χάρτης βάθους.
\end{itemize}

\subsection{Εκπαίδευση}
Η στρατηγική εκπαίδευσης του MiDaS είναι η κύρια καινοτομία του και παραμένει σταθερή σε όλες τις εκδόσεις, εξασφαλίζοντας την αρχιτεκτονική ανεξαρτησία της μεθόδου. Σχεδιάστηκε για να επιτύχει \textbf{Zero-shot Cross-dataset Transfer}, δηλαδή το μοντέλο αξιολογείται σε ένα test dataset το οποίο δεν είναι υποσύνολο του train dataset. 

Το μοντέλο εκπαιδεύτηκε συνδυάζοντας δεδομένα από \textbf{πολλαπλά και ετερογενή σύνολα (datasets)}, όπως ReDWeb, MegaDepth, DIML Indoor, WSVD και, κυρίως, μια νέα, μαζική πηγή από καρέ 3D ταινιών (3D Movies). Αυτή η ανάμειξη εξασφαλίζει ότι το μοντέλο εκτίθεται σε τεράστια ποικιλία σκηνών (πχ Indoor/Outdoor, Static/Dynamic), καθιστώντας τις αναπαραστάσεις που προσπαθεί να μάθει ανθεκτικές και γενικές. Χρησιμοποιήθηκε η τεχνική \textbf{Pareto-optimal Multi-objective Optimization (Βελτιστοποίηση Πολλαπλών Στόχων)} η οποία αντιμετωπίζει την εκπαίδευση σε κάθε dataset ως ξεχωριστό στόχο, εξασφαλίζοντας ισορροπημένη μάθηση ώστε η βελτίωση της απόδοσης σε ένα dataset να μην υποβαθμίζει την απόδοση σε κάποιο άλλο (φαινόμενο που παρατηρήθηκε σε πείραμα εκπαίδευσης με μια \textbf{αφελή - naive μέθοδο}).

Για να καταστεί δυνατή η συνεκπαίδευση σε datasets με ασύμβατες ετικέτες (πχ μετρικό βάθος έναντι σχετικού βάθους), το MiDaS παράγει τις προβλέψεις του στον χώρο της \textbf{Δυσαναλογίας (Disparity Space)} (δηλαδή του αντίστροφου βάθους, $\text{D}^{-1}$), ο οποίος είναι αριθμητικά σταθερός και συμβατός με τις όλες τις πηγές των ground truths σε όλα τα σύνολα δεδομένων. Για να το καταφέρει αυτό εισάγει μια καινοτόμο συνάρτηση απώλειας (Loss function). Χρησιμοποιείται η \textbf{Scale- and Shift-Invariant Trimmed MAE} ($\mathcal{L}_{ssitrim}$) η οποία είναι αδιάφορη ως προς την κλίμακα ($s$) και τη μετατόπιση ($t$) (scale- and shift-invariant), επιτρέποντας την εκπαίδευση σε ανομοιογενείς ετικέτες. Επιπλεόν, είναι ανθεκτική (robust), καθώς αποκόπτει (trims) το 20\% των ακραίων τιμών (outliers) σε κάθε εικόνα, μειώνοντας την ευαισθησία του μοντέλου σε μη ακριβή ετικέτες του ground truth.

Τέλος, η επιτυχία του MiDaS εξαρτάται και από τις τεχνικές \textbf{Transfer Learning} που εφαρμόστηκαν. Χρησιμοποιήθηκαν encoders υψηλής χωρητικότητας (π.χ., ResNeXt-101-WSL ή Vision Transformers) που είχαν προ-εκπαιδευτεί σε τεράστια σύνολα δεδομένων (π.χ., ImageNet ή Weakly-Supervised Data) πριν από την εκπαίδευση με στόχο την εκτίμηση του βάθους. Αυτή η προ-εκπαίδευση παρέχει στον κωδικοποιητή εξαιρετικά γενικεύσιμες αναπαραστάσεις των χαρακτηριστικών της εικόνας, οι οποίες μεταφέρονται στην εργασία εκτίμησης βάθους, ενισχύοντας την ικανότητα του μοντέλου να ερμηνεύει άγνωστες σκηνές.

\section{ZoeDepth: Zero-shot Transfer by Combining Relative and Metric Depth}
Το \textbf{ZoeDepth} αντιπροσωπεύει εξέλιξη της έρευνας του μοντέλου MiDaS. Ενώ τα MiDaS v1-v3 ήταν εξαιρετικά στην πρόβλεψη του σχετικού βάθους (relative depth) –δηλαδή τη σωστή διάταξη των αντικειμένων στο χώρο–, απέτυχαν να διατηρήσουν τη μετρική κλίμακα (metric scale) (πχ το πραγματικό βάθος σε μέτρα). Το ZoeDepth είναι η πρώτη προσέγγιση που συνδυάζει την γενίκευση του MiDaS με την ικανότητα διατήρησης της μετρικής κλίμακας \cite{bhat2023zoedepthzeroshottransfercombining}.

\subsection{Αρχιτεκτονική}
Το ZoeDepth διατηρεί την αρχιτεκτονική Κωδικοποιητή-Αποκωδικοποιητή, κληρονομώντας τις βέλτιστες πρακτικές του DPT. Προκειμένου να αντιμετωπίσει το μέχρι τότε δυσεπίλυτο πρόβλημα της απόλυτης εκτίμησης βάθους, εισάγει μια κρίσιμη καινοτομία στην κεφαλή πρόβλεψης, το \textbf{Metric Bins Module}.
\begin{itemize}
    \item \textbf{Κωδικοποιητής}: Όπως ακριβώς και το MiDaS v3, το ZoeDepth χρησιμοποιεί ViT ως backbone και συγκεκριμένα το \textbf{Beit-L}. Έτσι, όπως έχει αποδειχθεί, εξασφαλίζει την καλύτερη δυνατή γενίκευση και μοντελοποίηση των ολικών εξαρτήσεων στην εικόνα.
    \item \textbf{Αποκωδικοποιητής}: Ο αποκωδικοποιητής παραμένει παρόμοιος με αυτόν του DPT, αλλά με μια σημαντική καινοτομία - το \textbf{Metric Bins Module (MBM)}. Αντί να προβλέπει το βάθος ως μία συνεχή τιμή (regression), το ZoeDepth προβλέπει πιθανότητες βάθους σε ένα σύνολο \textbf{διακριτών bins}, τα οποία αναπαριστούν ένα συγκεκριμένο εύρος βάθους (πχ 0-80m για εξωτερικές σκηνές ή 0-10m για εσωτερικές). Το MBM επιτρέπει την προσαρμογή της θέσης αυτών των bins κατά τη διάρκεια της εκπαίδευσης με μετρικό βάθος (\textbf{metric depth fine-tuning}).
    \item \textbf{Router}: Επειδή το μοντέλο έχει γίνει fine-tune σε διαφορετικά datasets για εσωτερικές και εξωτερικές σκηνές και υπάρχουν επομένως, διαφορετικές κεφαλές (\textbf{Metric Heads}) για κάθε τύπο σκηνής. Έτσι, είναι αναγκαίο να υπάρχει ένας μηχανισμός που να επιλέγει την κατάλληλη κεφαλή ανάλογα με την είσοδο. Για αυτό το σκοπό, το ZoeDepth εισάγει έναν \textbf{Router}, ο οποίος αποτελείται από ένα \textbf{Multi Layer Perceptron (MLP)} ταξινομητή που εκπαιδεύεται ταυτόχρονα με το υπόλοιπο μοντέλο.
\end{itemize}

\subsection{Εκπαίδευση}
Η εκπαίδευση του ZoeDepth αναλύεται σε δύο φάσεις. Στην πρώτη φάση γίνεται ένα pre-train εμπνευσμένο από το MiDaS, ενώ στην δεύτερη φάση γίνεται το fine-tune που επιλύει το πρόβλημα της απόλυτης/μετρικής εκτίμησης βάθους.

\subsubsection{Φάση 1: Προ-εκπαίδευση Σχετικού Βάθους (Relative Depth Pre-training)}
Η πρώτη φάση ακολουθεί την  μεθοδολογία του MiDaS. Εκπαιδεύεται σε 12 datasets με ετικέτες \textbf{σχετικού βάθους} χρησιμοποιώντας την ίδια συνάρτηση απώλειας \textbf{Scale- and Shift-Invariant Loss}. Έτσι, χτίζεται ένας ισχυρά γενικεύσιμος κωδικοποιητής, ικανός να ερμηνεύει ποικίλα datasets.

\subsubsection{Φάση 2: Fine-tuning Μετρικού Βάθους (Metric Depth Fine-tuning)}
Η δεύτερη φάση εκπαίδευσης είναι μια διαδικασία fine-tuning, με στόχο την ευθυγράμμιση του ήδη γενικεύσιμου κωδικοποιητή με την πραγματική μετρική κλίμακα. Κατά τη διάρκεια αυτής της φάσης, το μοντέλο χρησιμοποιεί δύο υψηλής ποιότητας datasets που περιέχουν μετρικό ground truth -το \textbf{KITTI} για εξωτερικές σκηνές και το \textbf{NYU Depth V2} για εσωτερικές.

Ουσιαστικά, η εκπαίδευση επικεντρώνεται στο Metric Bins Module (MBM), την νέα κεφαλή του μοντέλου. Ενώ στην πρώτη φάση το μοντέλο έμαθε να τοποθετεί τα αντικείμενα σωστά σε σχετικό βάθος, στη δεύτερη φάση το MBM ενεργοποιείται και βελτιστοποιείται. Το μοντέλο μαθαίνει να προσαρμόζει τις εκπαιδεύσιμες παραμέτρους που ορίζουν τα όρια των διακριτών metric bins, ώστε να αντιστοιχούν ακριβέστερα στις πραγματικές μετρικές τιμές.

Χρησιμοποιώντας μια τυπική μετρική συνάρτηση απώλειας (metric loss), το μοντέλο μαθαίνει την σωστή κλίμακα, επιτυγχάνοντας πλέον ακριβή πρόβλεψη βάθους σε μέτρα. Το αποτέλεσμα είναι ένα μοντέλο που διατηρεί την εξαιρετική ικανότητα zero-shot transfer που αποκτήθηκε από την προ-εκπαίδευση, ενώ ταυτόχρονα μπορεί να δίνει αξιόπιστες μετρικές τιμές σε διαφορετικού είδους εικόνες εισόδου.

\pagebreak
\printbibliography

\end{document}
