{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11903193,"sourceType":"datasetVersion","datasetId":7482501}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers diffusers imageio scipy timm accelerate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T17:41:56.371276Z","iopub.execute_input":"2026-01-05T17:41:56.371923Z","iopub.status.idle":"2026-01-05T17:41:59.718353Z","shell.execute_reply.started":"2026-01-05T17:41:56.371893Z","shell.execute_reply":"2026-01-05T17:41:59.717174Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import os\nimport cv2\nimport glob\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\nfrom scipy.io import loadmat\nfrom diffusers import MarigoldDepthPipeline\nfrom transformers import AutoImageProcessor, AutoModelForDepthEstimation, ZoeDepthForDepthEstimation","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T18:51:44.254351Z","iopub.execute_input":"2026-01-05T18:51:44.255013Z","iopub.status.idle":"2026-01-05T18:51:44.259042Z","shell.execute_reply.started":"2026-01-05T18:51:44.254984Z","shell.execute_reply":"2026-01-05T18:51:44.258431Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"IBIMS_PATH = \"/kaggle/input/ibims-1/iBims-1\"\n\nDEVICE = torch.device(\"cuda\") if torch.cuda.is_available else torch.device(\"cpu\")\nprint(DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T18:31:46.619016Z","iopub.execute_input":"2026-01-05T18:31:46.619726Z","iopub.status.idle":"2026-01-05T18:31:46.624736Z","shell.execute_reply.started":"2026-01-05T18:31:46.619689Z","shell.execute_reply":"2026-01-05T18:31:46.624006Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# https://www.asg.ed.tum.de/lmf/ibims1/\n\nclass IBimsLoader:\n    def __init__(self, root_dir=IBIMS_PATH):\n        self.rgb_files = sorted(glob.glob(os.path.join(root_dir, \"rgb\", \"*.png\")))\n        self.depth_files = sorted(glob.glob(os.path.join(root_dir, \"ibims1_core_mat\", \"*.mat\")))\n        \n        if len(self.rgb_files) != len(self.depth_files):\n            print(\"Hmm something is wrong with the dataset...\")\n\n    def __len__(self):\n        return len(self.rgb_files)\n\n    def get_item(self, idx):\n        img_path = self.rgb_files[idx]\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        depth_path = self.depth_files[idx]\n        mat_data = loadmat(depth_path)\n        \n        key = [k for k in mat_data.keys() if not k.startswith('_')][0]\n        data_struct = mat_data[key][0, 0]\n        \n        gt_depth = data_struct['depth']\n        gt_depth = gt_depth.astype(np.float32)\n\n        invalid_mask = data_struct['mask_invalid'].astype(bool)\n        \n        return img, gt_depth, invalid_mask, os.path.basename(img_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T19:31:10.007441Z","iopub.execute_input":"2026-01-05T19:31:10.007974Z","iopub.status.idle":"2026-01-05T19:31:10.014139Z","shell.execute_reply.started":"2026-01-05T19:31:10.007945Z","shell.execute_reply":"2026-01-05T19:31:10.013491Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"class DepthMetrics:\n    def __init__(self):\n        pass\n\n    def align_scale_shift(self, pred, target):\n        \"\"\"\n        MiDaS paper - p.5\n        Aligns prediction to target using Least Squares (Scale & Shift).\n        Used for Relative Depth Models (MiDaS, Depth Anything Base).\n        Formula: s*, t* = argmin || s * pred + t - target ||^2\n        \"\"\"\n        mask = (target > 0)\n        target_masked = target[mask]\n        pred_masked = pred[mask]\n\n        if len(pred_masked) < 10: return pred, 1.0, 0.0\n        \n        slope, intercept = np.polyfit(pred_masked, target_masked, 1)\n        \n        pred_aligned = pred * slope + intercept\n        return pred_aligned, slope, intercept\n\n    def align_median(self, pred, target):\n        \"\"\"\n        Simple Median Scaling. often used for Metric models to correct global scale drift.\n        \"\"\"\n        mask = (target > 0)\n        scale = np.median(target[mask]) / np.median(pred[mask])\n        return pred * scale\n\n    def compute(self, pred, target, invalid_mask=None, align_type=\"none\"):\n        \"\"\"\n        Calculates: AbsRel, RMSE, Delta1 (a1).\n        align_type: 'none' (for Metric League), 'least_squares' (for Relative League)\n        \"\"\"\n        valid_mask = invalid_mask if invalid_mask is not None else np.ones_like(target, dtype=bool)\n        \n        # GT > 0.1 ensures we don't divide by tiny numbers\n        # GT < 80.0 removes infinite sky/sensor errors\n        valid_mask = valid_mask & (target > 0.1) & (target < 80.0)\n        \n        valid_mask = valid_mask & (~np.isnan(target)) & (~np.isnan(pred))\n        if valid_mask.sum() == 0: return None\n\n        pred_valid = pred[valid_mask]\n        target_valid = target[valid_mask]\n\n        if align_type == \"least_squares\":\n            pred_valid, _, _ = self.align_scale_shift(pred_valid, target_valid)\n        elif align_type == \"median\":\n            scale = np.median(target_valid) / np.median(pred_valid)\n            pred_valid = pred_valid * scale\n\n        pred_valid = np.clip(pred_valid, 0.001, 80.0)\n\n        # AbsRel: |pred - gt| / gt\n        abs_rel = np.mean(np.abs(pred_valid - target_valid) / target_valid)\n\n        # RMSE\n        rmse = np.sqrt(np.mean((pred_valid - target_valid) ** 2))\n\n        # Delta Accuracy: max(pred/gt, gt/pred) < 1.25\n        thresh = np.maximum((target_valid / pred_valid), (pred_valid / target_valid))\n        a1 = (thresh < 1.25).mean()\n\n        return {\"abs_rel\": abs_rel, \"rmse\": rmse, \"a1\": a1}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T19:36:25.692633Z","iopub.execute_input":"2026-01-05T19:36:25.692921Z","iopub.status.idle":"2026-01-05T19:36:25.701054Z","shell.execute_reply.started":"2026-01-05T19:36:25.692895Z","shell.execute_reply":"2026-01-05T19:36:25.700513Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"class TransformerModelWrapper:\n    def __init__(self, choice):\n        self.processor = AutoImageProcessor.from_pretrained(choice)\n        self.model = AutoModelForDepthEstimation.from_pretrained(choice).to(DEVICE)\n\n    def infer(self, image_path):\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        inputs = self.processor(images=image, return_tensors=\"pt\").to(DEVICE)\n        \n        with torch.no_grad():\n            outputs = self.model(**inputs)\n            predicted_depth = outputs.predicted_depth\n        \n        # Resize to original image size\n        prediction = torch.nn.functional.interpolate(\n            predicted_depth.unsqueeze(1),\n            size=image.shape[:2],\n            mode=\"bicubic\",\n            align_corners=False,\n        ).squeeze().cpu().numpy()\n        \n        return prediction\n\nclass ModelRunner:\n    def __init__(self, device=\"cuda\"):\n        self.device = device\n        self.models = {}\n        self.processors = {}\n    \n    def load_depth_anything_v2(self, variant=\"metric\"):\n        if variant == \"metric\":\n            mid = \"depth-anything/Depth-Anything-V2-Metric-Indoor-Large-hf\"\n        else:\n            mid = \"depth-anything/Depth-Anything-V2-Small-hf\"\n            \n        print(f\"Loading {mid}...\")\n        self.processors[\"da_v2\"] = AutoImageProcessor.from_pretrained(mid)\n        self.models[\"da_v2\"] = AutoModelForDepthEstimation.from_pretrained(mid).to(self.device)\n    \n    def load_zoedepth(self):\n        print(\"Loading ZoeDepth...\")\n        mid = \"intel-isl/ZoeD_M12_N\"\n        self.processors[\"zoe\"] = AutoImageProcessor.from_pretrained(mid)\n        self.models[\"zoe\"] = ZoeDepthForDepthEstimation.from_pretrained(mid).to(self.device)\n\n    def load_marigold(self):\n        print(\"Loading Marigold (Diffusion)...\")\n        pipe = MarigoldDepthPipeline.from_pretrained(\n            \"prs-eth/marigold-v1-0\", torch_dtype=torch.float16\n        )\n        pipe.to(self.device)\n        self.models[\"marigold\"] = pipe\n\n    def infer(self, model_name, image_path):\n        \"\"\"\n        Generic inference wrapper\n        \"\"\"\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if model_name == \"marigold\":\n            from PIL import Image\n            pil_img = Image.fromarray(image)\n            pipe_out = self.models[\"marigold\"](pil_img, num_inference_steps=10) # 10 is fast, 50 is precise\n            depth = pipe_out.depth_np\n            return depth\n\n        processor = self.processors[model_name]\n        model = self.models[model_name]\n        \n        inputs = processor(images=image, return_tensors=\"pt\").to(self.device)\n        \n        with torch.no_grad():\n            outputs = model(**inputs)\n            predicted_depth = outputs.predicted_depth\n        \n        # Resize to original image size\n        prediction = torch.nn.functional.interpolate(\n            predicted_depth.unsqueeze(1),\n            size=image.shape[:2],\n            mode=\"bicubic\",\n            align_corners=False,\n        ).squeeze().cpu().numpy()\n        \n        return prediction","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T19:19:40.143996Z","iopub.execute_input":"2026-01-05T19:19:40.144524Z","iopub.status.idle":"2026-01-05T19:19:40.154944Z","shell.execute_reply.started":"2026-01-05T19:19:40.144492Z","shell.execute_reply":"2026-01-05T19:19:40.154384Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"def get_final_results(results):\n    if len(results) > 0:\n        print(\"\\n\" + \"=\"*40)\n        \n        avg_results = {}\n        for key in results[0].keys():\n            avg_results[key] = np.mean([res[key] for res in results])\n    \n        print(f\"AbsRel (Lower is better):  {avg_results['abs_rel']:.4f}\")\n        print(f\"RMSE   (Lower is better):  {avg_results['rmse']:.4f}\")\n        print(f\"Delta1 (Higher is better): {avg_results['a1']:.4f}\")\n        print(\"=\"*40)\n        return avg_results\n    else:\n        print(\"No valid results found.\")\n    return None\n\ndef run_transformer_over_dataset(model, dataset, metrics_calc, align_type=\"none\", debug=False):\n    results = []\n    for i in tqdm(range(len(dataset))):\n        img, gt, mask, name = dataset.get_item(i)\n        #print(img.shape, gt.shape, name)\n        image_path = f\"{IBIMS_PATH}/rgb/{name}\"\n        \n        prediction = dav2_base.infer(image_path)\n        metrics = metrics_calc.compute(prediction, gt, invalid_mask=mask, align_type=align_type)\n        if metrics is not None:\n            results.append(metrics)\n            if debug: \n                print(f\"{name}\\tAbsRel: {metrics['abs_rel']:.3f}\\tRMSE: {metrics['rmse']:.3f}\\tDelta1: {metrics['a1']:.3f}\")\n                print(f\"Pred Median: {np.median(prediction):.2f}, GT Median: {np.median(gt):.2f}\")\n        else:\n            print(f\"Something went wrong with {name}. Skipping...\")\n    \n    return get_final_results(results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T19:27:53.362928Z","iopub.execute_input":"2026-01-05T19:27:53.363338Z","iopub.status.idle":"2026-01-05T19:27:53.370080Z","shell.execute_reply.started":"2026-01-05T19:27:53.363310Z","shell.execute_reply":"2026-01-05T19:27:53.369548Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"dataset = IBimsLoader()\nmetrics_calc = DepthMetrics()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T19:36:31.275424Z","iopub.execute_input":"2026-01-05T19:36:31.275734Z","iopub.status.idle":"2026-01-05T19:36:31.283535Z","shell.execute_reply.started":"2026-01-05T19:36:31.275707Z","shell.execute_reply":"2026-01-05T19:36:31.282984Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"img, gt, invalid_mask, name = dataset.get_item(12)\nprint(np.where(invalid_mask == True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T19:33:15.642296Z","iopub.execute_input":"2026-01-05T19:33:15.642566Z","iopub.status.idle":"2026-01-05T19:33:15.685054Z","shell.execute_reply.started":"2026-01-05T19:33:15.642544Z","shell.execute_reply":"2026-01-05T19:33:15.684503Z"}},"outputs":[{"name":"stdout","text":"(array([  0,   0,   0, ..., 479, 479, 479]), array([  0,   1,   2, ..., 637, 638, 639]))\n","output_type":"stream"}],"execution_count":73},{"cell_type":"code","source":"# Check if dataset gt is in mm\nfor i in range(len(dataset)):\n    img, gt, invalid_mask, name = dataset.get_item(i)\n    if np.median(gt) > 100:\n        print(\"maybe that measurement is in millimeters... needs to change!\")\n    #print(np.where(invalid_mask == False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T19:35:30.626753Z","iopub.execute_input":"2026-01-05T19:35:30.627417Z","iopub.status.idle":"2026-01-05T19:35:34.403922Z","shell.execute_reply.started":"2026-01-05T19:35:30.627382Z","shell.execute_reply":"2026-01-05T19:35:34.403281Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"dav2_base = TransformerModelWrapper(\"depth-anything/Depth-Anything-V2-Small-hf\")\nrun_transformer_over_dataset(dav2_base, dataset, metrics_calc, align_type=\"least_squares\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T19:36:38.243225Z","iopub.execute_input":"2026-01-05T19:36:38.243932Z","iopub.status.idle":"2026-01-05T19:36:52.215879Z","shell.execute_reply.started":"2026-01-05T19:36:38.243900Z","shell.execute_reply":"2026-01-05T19:36:52.215325Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 100/100 [00:13<00:00,  7.44it/s]","output_type":"stream"},{"name":"stdout","text":"\n========================================\nAbsRel (Lower is better):  0.1192\nRMSE   (Lower is better):  0.5311\nDelta1 (Higher is better): 0.8536\n========================================\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"{'abs_rel': np.float64(0.11924478010784752),\n 'rmse': np.float64(0.5311465352130827),\n 'a1': np.float64(0.8535762321108398)}"},"metadata":{}}],"execution_count":79},{"cell_type":"code","source":"dav2_metric = TransformerModelWrapper(\"depth-anything/Depth-Anything-V2-Metric-Indoor-Large-hf\")\nrun_transformer_over_dataset(dav2_metric, dataset, metrics_calc, align_type=\"none\", debug=False)\n\n#print(\"\\nLet's apply some scaling to test what changes\")\n#run_transformer_over_dataset(dav2_metric, dataset, metrics_calc, align_type=\"median\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T19:37:14.843982Z","iopub.execute_input":"2026-01-05T19:37:14.844754Z","iopub.status.idle":"2026-01-05T19:37:27.126174Z","shell.execute_reply.started":"2026-01-05T19:37:14.844722Z","shell.execute_reply":"2026-01-05T19:37:27.125482Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 100/100 [00:11<00:00,  8.81it/s]","output_type":"stream"},{"name":"stdout","text":"\n========================================\nAbsRel (Lower is better):  0.9662\nRMSE   (Lower is better):  3.0890\nDelta1 (Higher is better): 0.1500\n========================================\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"{'abs_rel': np.float32(0.96617407),\n 'rmse': np.float32(3.0889754),\n 'a1': np.float64(0.14998329868036855)}"},"metadata":{}}],"execution_count":81},{"cell_type":"code","source":"run_transformer_over_dataset(dav2_metric, dataset, metrics_calc, align_type=\"median\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T19:37:50.993439Z","iopub.execute_input":"2026-01-05T19:37:50.993742Z","iopub.status.idle":"2026-01-05T19:38:02.660490Z","shell.execute_reply.started":"2026-01-05T19:37:50.993716Z","shell.execute_reply":"2026-01-05T19:38:02.659922Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 100/100 [00:11<00:00,  8.58it/s]","output_type":"stream"},{"name":"stdout","text":"\n========================================\nAbsRel (Lower is better):  1.2479\nRMSE   (Lower is better):  4.2113\nDelta1 (Higher is better): 0.2292\n========================================\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"{'abs_rel': np.float32(1.2478518),\n 'rmse': np.float32(4.2112966),\n 'a1': np.float64(0.22922321199906034)}"},"metadata":{}}],"execution_count":82}]}