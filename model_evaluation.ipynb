{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11903193,"sourceType":"datasetVersion","datasetId":7482501}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers diffusers imageio scipy timm accelerate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T17:41:56.371276Z","iopub.execute_input":"2026-01-05T17:41:56.371923Z","iopub.status.idle":"2026-01-05T17:41:59.718353Z","shell.execute_reply.started":"2026-01-05T17:41:56.371893Z","shell.execute_reply":"2026-01-05T17:41:59.717174Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import os\nimport cv2\nimport glob\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\nfrom scipy.io import loadmat\nfrom diffusers import MarigoldDepthPipeline\nfrom transformers import AutoImageProcessor, AutoModelForDepthEstimation, ZoeDepthForDepthEstimation","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T18:51:44.254351Z","iopub.execute_input":"2026-01-05T18:51:44.255013Z","iopub.status.idle":"2026-01-05T18:51:44.259042Z","shell.execute_reply.started":"2026-01-05T18:51:44.254984Z","shell.execute_reply":"2026-01-05T18:51:44.258431Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"IBIMS_PATH = \"/kaggle/input/ibims-1/iBims-1\"\n\nDEVICE = torch.device(\"cuda\") if torch.cuda.is_available else torch.device(\"cpu\")\nprint(DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T18:31:46.619016Z","iopub.execute_input":"2026-01-05T18:31:46.619726Z","iopub.status.idle":"2026-01-05T18:31:46.624736Z","shell.execute_reply.started":"2026-01-05T18:31:46.619689Z","shell.execute_reply":"2026-01-05T18:31:46.624006Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"class IBimsLoader:\n    def __init__(self, root_dir=IBIMS_PATH):\n        self.rgb_files = sorted(glob.glob(os.path.join(root_dir, \"rgb\", \"*.png\")))\n        self.depth_files = sorted(glob.glob(os.path.join(root_dir, \"ibims1_core_mat\", \"*.mat\")))\n        \n        # Verify alignment\n        if len(self.rgb_files) != len(self.depth_files):\n            print(\"Hmm something is wrong with the dataset...\")\n\n    def __len__(self):\n        return len(self.rgb_files)\n\n    def get_item(self, idx):\n        img_path = self.rgb_files[idx]\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        depth_path = self.depth_files[idx]\n        mat_data = loadmat(depth_path)\n        \n        key = [k for k in mat_data.keys() if not k.startswith('_')][0]\n        data_struct = mat_data[key][0, 0]\n        \n        gt_depth = data_struct['depth']\n        gt_depth = gt_depth.astype(np.float32)\n        \n        return img, gt_depth, os.path.basename(img_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T17:56:32.427497Z","iopub.execute_input":"2026-01-05T17:56:32.428196Z","iopub.status.idle":"2026-01-05T17:56:32.434201Z","shell.execute_reply.started":"2026-01-05T17:56:32.428166Z","shell.execute_reply":"2026-01-05T17:56:32.433323Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class DepthMetrics:\n    def __init__(self):\n        pass\n\n    def align_scale_shift(self, pred, target):\n        \"\"\"\n        MiDaS paper - p.5\n        Aligns prediction to target using Least Squares (Scale & Shift).\n        Used for Relative Depth Models (MiDaS, Depth Anything Base).\n        Formula: s*, t* = argmin || s * pred + t - target ||^2\n        \"\"\"\n        mask = (target > 0)\n        target_masked = target[mask]\n        pred_masked = pred[mask]\n\n        if len(pred_masked) < 10: return pred, 1.0, 0.0\n        \n        slope, intercept = np.polyfit(pred_masked, target_masked, 1)\n        \n        pred_aligned = pred * slope + intercept\n        return pred_aligned, slope, intercept\n\n    def align_median(self, pred, target):\n        \"\"\"\n        Simple Median Scaling. often used for Metric models to correct global scale drift.\n        \"\"\"\n        mask = (target > 0)\n        scale = np.median(target[mask]) / np.median(pred[mask])\n        return pred * scale\n\n    def compute(self, pred, target, align_type=\"none\"):\n        \"\"\"\n        Calculates: AbsRel, RMSE, Delta1 (a1).\n        align_type: 'none' (for Metric League), 'least_squares' (for Relative League)\n        \"\"\"\n        mask = (target > 0.001) & (target < 80.0) & (~np.isnan(target)) & (~np.isnan(pred))\n        \n        if mask.sum() == 0: return None\n\n        pred_valid = pred[mask]\n        target_valid = target[mask]\n\n        if align_type == \"least_squares\":\n            pred_valid, _, _ = self.align_scale_shift(pred_valid, target_valid)\n        elif align_type == \"median\":\n            scale = np.median(target_valid) / np.median(pred_valid)\n            pred_valid = pred_valid * scale\n\n        pred_valid = np.clip(pred_valid, 0.001, 80.0)\n\n        # AbsRel: |pred - gt| / gt\n        abs_rel = np.mean(np.abs(pred_valid - target_valid) / target_valid)\n\n        # RMSE\n        rmse = np.sqrt(np.mean((pred_valid - target_valid) ** 2))\n\n        # Delta Accuracy: max(pred/gt, gt/pred) < 1.25\n        thresh = np.maximum((target_valid / pred_valid), (pred_valid / target_valid))\n        a1 = (thresh < 1.25).mean()\n\n        return {\"abs_rel\": abs_rel, \"rmse\": rmse, \"a1\": a1}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T17:40:24.171776Z","iopub.execute_input":"2026-01-05T17:40:24.172066Z","iopub.status.idle":"2026-01-05T17:40:24.180739Z","shell.execute_reply.started":"2026-01-05T17:40:24.172039Z","shell.execute_reply":"2026-01-05T17:40:24.180128Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class TransformerModelWrapper:\n    def __init__(self, choice):\n        self.processor = AutoImageProcessor.from_pretrained(choice)\n        self.model = AutoModelForDepthEstimation.from_pretrained(choice).to(DEVICE)\n\n    def infer(self, image_path):\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        inputs = self.processor(images=image, return_tensors=\"pt\").to(DEVICE)\n        \n        with torch.no_grad():\n            outputs = self.model(**inputs)\n            predicted_depth = outputs.predicted_depth\n        \n        # Resize to original image size\n        prediction = torch.nn.functional.interpolate(\n            predicted_depth.unsqueeze(1),\n            size=image.shape[:2],\n            mode=\"bicubic\",\n            align_corners=False,\n        ).squeeze().cpu().numpy()\n        \n        return prediction\n\nclass ModelRunner:\n    def __init__(self, device=\"cuda\"):\n        self.device = device\n        self.models = {}\n        self.processors = {}\n    \n    def load_depth_anything_v2(self, variant=\"metric\"):\n        if variant == \"metric\":\n            mid = \"depth-anything/Depth-Anything-V2-Metric-Indoor-Large-hf\"\n        else:\n            mid = \"depth-anything/Depth-Anything-V2-Small-hf\"\n            \n        print(f\"Loading {mid}...\")\n        self.processors[\"da_v2\"] = AutoImageProcessor.from_pretrained(mid)\n        self.models[\"da_v2\"] = AutoModelForDepthEstimation.from_pretrained(mid).to(self.device)\n    \n    def load_zoedepth(self):\n        print(\"Loading ZoeDepth...\")\n        mid = \"intel-isl/ZoeD_M12_N\"\n        self.processors[\"zoe\"] = AutoImageProcessor.from_pretrained(mid)\n        self.models[\"zoe\"] = ZoeDepthForDepthEstimation.from_pretrained(mid).to(self.device)\n\n    def load_marigold(self):\n        print(\"Loading Marigold (Diffusion)...\")\n        pipe = MarigoldDepthPipeline.from_pretrained(\n            \"prs-eth/marigold-v1-0\", torch_dtype=torch.float16\n        )\n        pipe.to(self.device)\n        self.models[\"marigold\"] = pipe\n\n    def infer(self, model_name, image_path):\n        \"\"\"\n        Generic inference wrapper\n        \"\"\"\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if model_name == \"marigold\":\n            from PIL import Image\n            pil_img = Image.fromarray(image)\n            pipe_out = self.models[\"marigold\"](pil_img, num_inference_steps=10) # 10 is fast, 50 is precise\n            depth = pipe_out.depth_np\n            return depth\n\n        processor = self.processors[model_name]\n        model = self.models[model_name]\n        \n        inputs = processor(images=image, return_tensors=\"pt\").to(self.device)\n        \n        with torch.no_grad():\n            outputs = model(**inputs)\n            predicted_depth = outputs.predicted_depth\n        \n        # Resize to original image size\n        prediction = torch.nn.functional.interpolate(\n            predicted_depth.unsqueeze(1),\n            size=image.shape[:2],\n            mode=\"bicubic\",\n            align_corners=False,\n        ).squeeze().cpu().numpy()\n        \n        return prediction","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T18:42:47.661591Z","iopub.execute_input":"2026-01-05T18:42:47.662455Z","iopub.status.idle":"2026-01-05T18:42:47.678436Z","shell.execute_reply.started":"2026-01-05T18:42:47.662400Z","shell.execute_reply":"2026-01-05T18:42:47.677653Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"def get_final_results(results):\n    if len(results) > 0:\n        print(\"\\n\" + \"=\"*40)\n        \n        avg_results = {}\n        for key in results[0].keys():\n            avg_results[key] = np.mean([res[key] for res in results])\n    \n        print(f\"AbsRel (Lower is better):  {avg_results['abs_rel']:.4f}\")\n        print(f\"RMSE   (Lower is better):  {avg_results['rmse']:.4f}\")\n        print(f\"Delta1 (Higher is better): {avg_results['a1']:.4f}\")\n        print(\"=\"*40)\n        return avg_results\n    else:\n        print(\"No valid results found.\")\n    return None\n\ndef run_transformer_over_dataset(model, dataset, metrics_calc, debug=False):\n    results = []\n    for i in tqdm(range(len(dataset))):\n        img, gt, name = dataset.get_item(i)\n        #print(img.shape, gt.shape, name)\n        image_path = f\"{IBIMS_PATH}/rgb/{name}\"\n        \n        prediction = dav2_base.infer(image_path)\n        metrics = metrics_calc.compute(prediction, gt, align_type=\"least_squares\")\n        if metrics is not None:\n            results.append(metrics)\n            if debug: print(f\"{name}\\tAbsRel: {metrics['abs_rel']:.3f}\\tRMSE: {metrics['rmse']:.3f}\\tDelta1: {metrics['a1']:.3f}\")\n        else:\n            print(f\"Something went wrong with {name}. Skipping...\")\n    \n    return get_final_results(results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T18:52:48.870424Z","iopub.execute_input":"2026-01-05T18:52:48.871007Z","iopub.status.idle":"2026-01-05T18:52:48.878021Z","shell.execute_reply.started":"2026-01-05T18:52:48.870979Z","shell.execute_reply":"2026-01-05T18:52:48.877347Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"dataset = IBimsLoader()\nmetrics_calc = DepthMetrics()\n\ndav2_model = \"depth-anything/Depth-Anything-V2-Small-hf\"\ndav2_model_metric = \"depth-anything/Depth-Anything-V2-Metric-Indoor-Large-hf\"\n        \ndav2_base = TransformerModelWrapper(dav2_model)\n\nfinal_results = run_transformer_over_dataset(dav2_base, dataset, metrics_calc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T18:53:15.606785Z","iopub.execute_input":"2026-01-05T18:53:15.607070Z","iopub.status.idle":"2026-01-05T18:53:30.095015Z","shell.execute_reply.started":"2026-01-05T18:53:15.607046Z","shell.execute_reply":"2026-01-05T18:53:30.094240Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 100/100 [00:13<00:00,  7.16it/s]","output_type":"stream"},{"name":"stdout","text":"\n========================================\nAbsRel (Lower is better):  0.1194\nRMSE   (Lower is better):  0.5315\nDelta1 (Higher is better): 0.8534\n========================================\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":32}]}