{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11903193,"sourceType":"datasetVersion","datasetId":7482501}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers diffusers imageio scipy timm accelerate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T12:51:26.633984Z","iopub.execute_input":"2026-01-08T12:51:26.635012Z","iopub.status.idle":"2026-01-08T12:51:31.232906Z","shell.execute_reply.started":"2026-01-08T12:51:26.634977Z","shell.execute_reply":"2026-01-08T12:51:31.231979Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport cv2\nimport glob\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\nfrom scipy.io import loadmat\nfrom transformers import AutoImageProcessor, AutoModelForDepthEstimation","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T12:51:50.669710Z","iopub.execute_input":"2026-01-08T12:51:50.670620Z","iopub.status.idle":"2026-01-08T12:52:21.568364Z","shell.execute_reply.started":"2026-01-08T12:51:50.670571Z","shell.execute_reply":"2026-01-08T12:52:21.567418Z"}},"outputs":[{"name":"stderr","text":"2026-01-08 12:52:03.868758: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767876724.106527      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767876724.174237      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767876724.730660      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767876724.730704      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767876724.730707      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767876724.730710      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"IBIMS_PATH = \"/kaggle/input/ibims-1/iBims-1\"\n\nDEVICE = torch.device(\"cuda\") if torch.cuda.is_available else torch.device(\"cpu\")\nprint(DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T12:52:26.036911Z","iopub.execute_input":"2026-01-08T12:52:26.037595Z","iopub.status.idle":"2026-01-08T12:52:26.043744Z","shell.execute_reply.started":"2026-01-08T12:52:26.037561Z","shell.execute_reply":"2026-01-08T12:52:26.042756Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# https://www.asg.ed.tum.de/lmf/ibims1/\n\nclass IBimsLoader:\n    def __init__(self, root_dir=IBIMS_PATH):\n        self.rgb_files = sorted(glob.glob(os.path.join(root_dir, \"rgb\", \"*.png\")))\n        self.depth_files = sorted(glob.glob(os.path.join(root_dir, \"ibims1_core_mat\", \"*.mat\")))\n        \n        if len(self.rgb_files) != len(self.depth_files):\n            print(\"Hmm something is wrong with the dataset...\")\n\n    def __len__(self):\n        return len(self.rgb_files)\n\n    def get_item(self, idx):\n        img_path = self.rgb_files[idx]\n        img = cv2.imread(img_path)\n        #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        depth_path = self.depth_files[idx]\n        mat_data = loadmat(depth_path)\n\n        gt_depth = mat_data['data']['depth'][0][0]\n\n        mask = gt_depth > 0.001\n        \n        return img, gt_depth, mask, os.path.basename(img_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T12:52:31.928743Z","iopub.execute_input":"2026-01-08T12:52:31.929072Z","iopub.status.idle":"2026-01-08T12:52:31.935769Z","shell.execute_reply.started":"2026-01-08T12:52:31.929043Z","shell.execute_reply":"2026-01-08T12:52:31.934651Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def get_absrel(gt, pred):\n    return np.mean(np.abs(gt-pred)/gt)\n\ndef get_delta(gt, pred, exponent=1):\n    inlier = np.maximum((gt/pred), (pred/gt))\n    return np.mean(inlier < 1.25**exponent)\n\ndef align_depth_least_square(gt_arr, pred_arr, valid_mask_arr):\n    ori_shape = pred_arr.shape\n\n    gt = gt_arr.squeeze()  # [H, W]\n    pred = pred_arr.squeeze()\n    valid_mask = valid_mask_arr.squeeze()\n    gt_masked = gt[valid_mask].reshape((-1, 1))\n    pred_masked = pred[valid_mask].reshape((-1, 1))\n\n    # numpy solver\n    _ones = np.ones_like(pred_masked)\n    A = np.concatenate([pred_masked, _ones], axis=-1)\n    X = np.linalg.lstsq(A, gt_masked, rcond=None)[0]\n    scale, shift = X\n\n    aligned_pred = pred_arr * scale + shift\n\n    # restore dimensions\n    aligned_pred = aligned_pred.reshape(ori_shape)\n\n    return aligned_pred, scale, shift","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T12:52:34.629463Z","iopub.execute_input":"2026-01-08T12:52:34.629803Z","iopub.status.idle":"2026-01-08T12:52:34.637198Z","shell.execute_reply.started":"2026-01-08T12:52:34.629773Z","shell.execute_reply":"2026-01-08T12:52:34.636183Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class TransformerModelWrapper:\n    def __init__(self, choice):\n        self.processor = AutoImageProcessor.from_pretrained(choice)\n        self.model = AutoModelForDepthEstimation.from_pretrained(choice).to(DEVICE)\n\n    def infer(self, image_path):\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        inputs = self.processor(images=image, return_tensors=\"pt\").to(DEVICE)\n        \n        with torch.no_grad():\n            outputs = self.model(**inputs)\n            predicted_depth = outputs.predicted_depth\n        \n        # Resize to original image size\n        prediction = torch.nn.functional.interpolate(\n            predicted_depth.unsqueeze(1),\n            size=image.shape[:2],\n            mode=\"bicubic\",\n            align_corners=False,\n        ).squeeze().cpu().numpy()\n        \n        return prediction","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T12:52:37.541729Z","iopub.execute_input":"2026-01-08T12:52:37.542491Z","iopub.status.idle":"2026-01-08T12:52:37.550625Z","shell.execute_reply.started":"2026-01-08T12:52:37.542448Z","shell.execute_reply":"2026-01-08T12:52:37.549705Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Check if dataset gt is in mm\nfor i in range(len(dataset)):\n    _, gt, _, _ = dataset.get_item(i)\n    if np.median(gt) > 100:\n        print(\"maybe that measurement is in millimeters... needs to change!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T19:35:30.626753Z","iopub.execute_input":"2026-01-05T19:35:30.627417Z","iopub.status.idle":"2026-01-05T19:35:34.403922Z","shell.execute_reply.started":"2026-01-05T19:35:30.627382Z","shell.execute_reply":"2026-01-05T19:35:34.403281Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"ibims = IBimsLoader()\n\ndef benchmark(model, dataset, relative=True):\n    absrel_list = []\n    delta_list = []\n    \n    for i in tqdm(range(len(dataset))):\n        img, gt, mask, name = dataset.get_item(i)\n        image_path = f\"{IBIMS_PATH}/rgb/{name}\"\n            \n        prediction = model.infer(image_path)\n        if relative:\n            depth_trans, _, _ = align_depth_least_square(gt, prediction, mask)\n            absrel = get_absrel(gt[mask], depth_trans[mask])\n            delta = get_delta(gt[mask], depth_trans[mask], 1)\n        else:\n            absrel = get_absrel(gt[mask], prediction[mask])\n            delta = get_delta(gt[mask], prediction[mask], 1)\n    \n        absrel_list.append(absrel)\n        delta_list.append(delta)\n    \n    print(f\"Average Abs Rel: {np.mean(absrel_list)}\")\n    print(f\"Average d_1: {np.mean(delta_list)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T12:52:40.762638Z","iopub.execute_input":"2026-01-08T12:52:40.762978Z","iopub.status.idle":"2026-01-08T12:52:40.788153Z","shell.execute_reply.started":"2026-01-08T12:52:40.762949Z","shell.execute_reply":"2026-01-08T12:52:40.787271Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"benchmark(TransformerModelWrapper(\"depth-anything/Depth-Anything-V2-Large-hf\"), ibims)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T12:52:43.634527Z","iopub.execute_input":"2026-01-08T12:52:43.634932Z","iopub.status.idle":"2026-01-08T12:53:32.642665Z","shell.execute_reply.started":"2026-01-08T12:52:43.634894Z","shell.execute_reply":"2026-01-08T12:53:32.641834Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/775 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1da509042ba64b00a7f0196cd524c690"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f42e619e0b8144fe9d793f817b11b2b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50940852095b464e9766385a476d57a5"}},"metadata":{}},{"name":"stderr","text":"100%|██████████| 100/100 [00:42<00:00,  2.34it/s]","output_type":"stream"},{"name":"stdout","text":"Average Abs Rel: 0.1252612876460376\nAverage d_1: 0.8572297850934841\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"benchmark(TransformerModelWrapper(\"depth-anything/Depth-Anything-V2-Metric-Indoor-Large-hf\"), ibims, relative=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T12:53:37.983985Z","iopub.execute_input":"2026-01-08T12:53:37.984389Z","iopub.status.idle":"2026-01-08T12:54:23.896845Z","shell.execute_reply.started":"2026-01-08T12:53:37.984351Z","shell.execute_reply":"2026-01-08T12:54:23.896009Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/437 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fbbeeafb1eb474fa9a1e2074712fea5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c54a0adb6785462194c494b54ccb4b46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f207c5b5e1a43a487b605c2656855e2"}},"metadata":{}},{"name":"stderr","text":"100%|██████████| 100/100 [00:38<00:00,  2.60it/s]","output_type":"stream"},{"name":"stdout","text":"Average Abs Rel: 0.1264849104849234\nAverage d_1: 0.886137028246952\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":9}]}