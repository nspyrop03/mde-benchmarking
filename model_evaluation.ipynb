{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11903193,"sourceType":"datasetVersion","datasetId":7482501},{"sourceId":2002504,"sourceType":"datasetVersion","datasetId":1198025}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport glob\nimport torch\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom scipy.io import loadmat\nfrom diffusers import MarigoldDepthPipeline\nfrom transformers import AutoImageProcessor, AutoModelForDepthEstimation, ZoeDepthForDepthEstimation","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T15:40:13.418687Z","iopub.execute_input":"2026-01-09T15:40:13.419308Z","iopub.status.idle":"2026-01-09T15:40:48.614590Z","shell.execute_reply.started":"2026-01-09T15:40:13.419276Z","shell.execute_reply":"2026-01-09T15:40:48.613952Z"}},"outputs":[{"name":"stderr","text":"2026-01-09 15:40:34.201605: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767973234.399527      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767973234.456964      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767973234.907353      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767973234.907395      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767973234.907398      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767973234.907401      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"IBIMS_PATH = \"/kaggle/input/ibims-1/iBims-1\"\nNYU_PATH = \"/kaggle/input/nyu-depth-v2/nyu_data/data/nyu2_test\"\n\nDEVICE = torch.device(\"cuda\") if torch.cuda.is_available else torch.device(\"cpu\")\nprint(DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T15:40:48.615797Z","iopub.execute_input":"2026-01-09T15:40:48.616323Z","iopub.status.idle":"2026-01-09T15:40:48.620888Z","shell.execute_reply.started":"2026-01-09T15:40:48.616295Z","shell.execute_reply":"2026-01-09T15:40:48.620206Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# https://www.asg.ed.tum.de/lmf/ibims1/\n\nclass IBimsLoader:\n    def __init__(self, root_dir=IBIMS_PATH):\n        self.rgb_files = sorted(glob.glob(os.path.join(root_dir, \"rgb\", \"*.png\")))\n        self.depth_files = sorted(glob.glob(os.path.join(root_dir, \"ibims1_core_mat\", \"*.mat\")))\n        \n        if len(self.rgb_files) != len(self.depth_files):\n            print(\"Hmm something is wrong with the dataset...\")\n\n    def __len__(self):\n        return len(self.rgb_files)\n\n    def get_item(self, idx):\n        img_path = self.rgb_files[idx]\n        img = cv2.imread(img_path)\n        #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        depth_path = self.depth_files[idx]\n        mat_data = loadmat(depth_path)\n\n        gt_depth = mat_data['data']['depth'][0][0]\n\n        mask = gt_depth > 0.001\n        \n        return img, gt_depth, mask,img_path\n\nclass NyuLoader:\n    def __init__(self, root_dir=NYU_PATH, samples_size=100, seed=42):\n        self.samples = []\n        \n        self.rgb_files = sorted(glob.glob(os.path.join(root_dir, \"*_colors.png\"), recursive=True))\n        print(f\"Found {len(self.rgb_files)} RGB candidates. Matching with Depth...\")\n\n        for rgb_path in self.rgb_files:\n            depth_path = rgb_path.replace(\"_colors.png\", \"_depth.png\")\n            if os.path.exists(depth_path):\n                self.samples.append((rgb_path, depth_path))\n\n        if samples_size is not None and len(self.samples) > samples_size:\n            random.seed(seed)\n            self.samples = random.sample(self.samples, samples_size)\n    \n    def __len__(self):\n        return len(self.samples)\n\n    def get_item(self, idx):\n        img_path, depth_path = self.samples[idx]\n        \n        img = cv2.imread(img_path)\n        depth_png = cv2.imread(depth_path, -1)\n        if depth_png is None:\n            raise ValueError(f\"Failed to load depth: {depth_path}\")\n\n        gt_depth = depth_png.astype(np.float32) / 1000.0\n        mask = gt_depth > 0.001\n\n        return img, gt_depth, mask, img_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T15:40:48.621645Z","iopub.execute_input":"2026-01-09T15:40:48.621854Z","iopub.status.idle":"2026-01-09T15:40:48.643092Z","shell.execute_reply.started":"2026-01-09T15:40:48.621832Z","shell.execute_reply":"2026-01-09T15:40:48.642428Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"#  https://huggingface.co/blog/Isayoften/monocular-depth-estimation-guide\n\ndef get_absrel(gt, pred):\n    return np.mean(np.abs(gt-pred)/gt)\n\ndef get_delta(gt, pred, exponent=1):\n    inlier = np.maximum((gt/pred), (pred/gt))\n    return np.mean(inlier < 1.25**exponent)\n\ndef get_silog(gt, pred):\n    \"\"\"\n    Computes Scale Invariant Logarithmic Error.\n    Lower is better.\n    \"\"\"\n    pred = np.maximum(pred, 1e-5)\n    gt = np.maximum(gt, 1e-5)\n\n    err = np.log(pred) - np.log(gt)\n\n    silog = np.sqrt(np.mean(err ** 2) - (np.mean(err)) ** 2)\n    \n    return silog * 100\n\ndef align_depth_least_square(gt_arr, pred_arr, valid_mask_arr):\n    ori_shape = pred_arr.shape\n\n    gt = gt_arr.squeeze()  # [H, W]\n    pred = pred_arr.squeeze()\n    valid_mask = valid_mask_arr.squeeze()\n    gt_masked = gt[valid_mask].reshape((-1, 1))\n    pred_masked = pred[valid_mask].reshape((-1, 1))\n\n    # numpy solver\n    _ones = np.ones_like(pred_masked)\n    A = np.concatenate([pred_masked, _ones], axis=-1)\n    X = np.linalg.lstsq(A, gt_masked, rcond=None)[0]\n    scale, shift = X\n\n    aligned_pred = pred_arr * scale + shift\n\n    # restore dimensions\n    aligned_pred = aligned_pred.reshape(ori_shape)\n\n    return aligned_pred, scale, shift","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T16:01:28.272548Z","iopub.execute_input":"2026-01-09T16:01:28.273364Z","iopub.status.idle":"2026-01-09T16:01:28.280302Z","shell.execute_reply.started":"2026-01-09T16:01:28.273329Z","shell.execute_reply":"2026-01-09T16:01:28.279725Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class ModelWrapper:\n    def __init__(self, choice):\n        self.choice = choice\n        \n        if \"marigold\" in choice.lower():\n            self.model = MarigoldDepthPipeline.from_pretrained(choice, variant=\"fp16\").to(DEVICE)\n            self.model.set_progress_bar_config(disable=True)\n            print(\"found marigold model\")\n        elif \"zoedepth\" in choice.lower():\n            self.processor = AutoImageProcessor.from_pretrained(choice)\n            self.model = ZoeDepthForDepthEstimation.from_pretrained(choice).to(DEVICE)\n            print(\"found zoedepth model\")\n        else:\n            self.processor = AutoImageProcessor.from_pretrained(choice)\n            self.model = AutoModelForDepthEstimation.from_pretrained(choice).to(DEVICE)\n\n    def infer(self, image_path, marigold_steps=4):\n        if \"marigold\" in self.choice.lower():\n            image = Image.open(image_path).convert(\"RGB\")\n            w0, h0 = image.size\n            \n            with torch.no_grad():\n                pipe_out = self.model(\n                    image, \n                    num_inference_steps=marigold_steps, \n                    output_type=\"pt\"\n                )\n            prediction = pipe_out.prediction\n\n            # Check if resize is needed\n            if prediction.shape[-2:] != (h0, w0):\n                prediction = torch.nn.functional.interpolate(\n                    prediction,\n                    size=(h0, w0),\n                    mode=\"bicubic\",\n                    align_corners=False\n                )\n\n            return prediction.squeeze().cpu().numpy()\n\n        # Transformer-based models inference\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        inputs = self.processor(images=image, return_tensors=\"pt\").to(DEVICE)\n        \n        with torch.no_grad():\n            outputs = self.model(**inputs)\n            predicted_depth = outputs.predicted_depth\n        \n        # Resize to original image size\n        prediction = torch.nn.functional.interpolate(\n            predicted_depth.unsqueeze(1),\n            size=image.shape[:2],\n            mode=\"bicubic\",\n            align_corners=False,\n        )\n        \n        return prediction.squeeze().cpu().numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T15:40:48.662147Z","iopub.execute_input":"2026-01-09T15:40:48.662471Z","iopub.status.idle":"2026-01-09T15:40:48.680985Z","shell.execute_reply.started":"2026-01-09T15:40:48.662435Z","shell.execute_reply":"2026-01-09T15:40:48.680189Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Check if dataset gt is in mm\n# dataset = ...\nfor i in range(len(dataset)):\n    _, gt, _, _ = dataset.get_item(i)\n    if np.median(gt) > 100:\n        print(\"maybe that measurement is in millimeters... needs to change!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T19:35:30.626753Z","iopub.execute_input":"2026-01-05T19:35:30.627417Z","iopub.status.idle":"2026-01-05T19:35:34.403922Z","shell.execute_reply.started":"2026-01-05T19:35:30.627382Z","shell.execute_reply":"2026-01-05T19:35:34.403281Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"ibims_loader = IBimsLoader()\nnyu_loader = NyuLoader()\n\nclass ModelConfig:\n    def __init__(self, model_choice, display_name, relative=True, ibims=ibims_loader, nyu=nyu_loader):\n        self.model = ModelWrapper(model_choice)\n        self.display_name = display_name\n        self.relative = relative\n        self.ibims = ibims\n        self.nyu = nyu\n        self.absrel = {}\n        self.d1 = {}\n        self.silog = {}\n\n    def set_results(self, dataset, absrel, d1, silog):\n        self.absrel[dataset] = absrel;\n        self.d1[dataset] = d1\n        self.silog[dataset] = silog\n\n    def get_absrel_result(self, dataset):\n        return self.absrel[dataset]\n\n    def get_d1_result(self, dataset):\n        return self.d1[dataset]\n\n    def get_silog_result(self, dataset):\n        return self.silog[dataset]\n\n    def __basic_benchmark(self, dataset, debug=True):\n        absrel_list = []\n        delta_list = []\n        silog_list = []\n        \n        ds = \"ibims\"\n        if isinstance(dataset, NyuLoader):\n            ds = \"nyu\"\n            \n        for i in tqdm(range(len(dataset))):\n            _, gt, mask, image_path = dataset.get_item(i)\n            prediction = self.model.infer(image_path)\n\n            if self.relative:\n                depth, _, _ = align_depth_least_square(gt, prediction, mask)\n                absrel = get_absrel(gt[mask], depth[mask])\n                delta = get_delta(gt[mask], depth[mask], 1)\n                silog = get_silog(gt[mask], depth[mask])\n            else:\n                absrel = get_absrel(gt[mask], prediction[mask])\n                delta = get_delta(gt[mask], prediction[mask], 1)\n                silog = get_silog(gt[mask], prediction[mask])\n\n            absrel_list.append(absrel)\n            delta_list.append(delta)\n            silog_list.append(silog)\n            \n        am = np.mean(absrel_list)\n        dm = np.mean(delta_list)\n        sm = np.mean(silog_list)\n        self.set_results(ds, am, dm, sm)\n\n        if debug:\n            print(f\"\\tAverage AbsRel = {am:.4f}\")\n            print(f\"\\tAverage Delta1 = {dm:.4f}\")\n            print(f\"\\tAverage SILog  = {sm:.4f}\")\n\n    def benchmark(self, debug=True):\n        print(f\"{'='*20}[ {self.display_name} ]{'='*20}\")\n        if self.ibims is not None:\n            print(\"IBims-1 dataset:\")\n            self.__basic_benchmark(self.ibims, debug=debug)\n        if self.nyu is not None:\n            print(\"NYU Depth V2 dataset:\")\n            self.__basic_benchmark(self.nyu, debug=debug)\n        print(f\"{'='*20}[ {self.display_name} ]{'='*20}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T16:12:39.081069Z","iopub.execute_input":"2026-01-09T16:12:39.081633Z","iopub.status.idle":"2026-01-09T16:12:39.490027Z","shell.execute_reply.started":"2026-01-09T16:12:39.081598Z","shell.execute_reply":"2026-01-09T16:12:39.489410Z"}},"outputs":[{"name":"stdout","text":"Found 654 RGB candidates. Matching with Depth...\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"configs = [\n    ModelConfig(\"depth-anything/Depth-Anything-V2-Large-hf\", \"DAV2-Large\"),\n    ModelConfig(\"depth-anything/Depth-Anything-V2-Metric-Indoor-Large-hf\", \"DAV2-Indoor-Metric\", relative=False)\n]\n\nfor config in configs:\n    config.benchmark(debug=True)\n\n# TO-DO: Search Eigen-Crop technique to fix the results!","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T16:12:43.242463Z","iopub.execute_input":"2026-01-09T16:12:43.242810Z","iopub.status.idle":"2026-01-09T16:15:17.448941Z","shell.execute_reply.started":"2026-01-09T16:12:43.242783Z","shell.execute_reply":"2026-01-09T16:15:17.448286Z"}},"outputs":[{"name":"stdout","text":"====================[ DAV2-Large ]====================\nIBims-1 dataset:\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:41<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"\tAverage AbsRel = 0.1253\n\tAverage Delta1 = 0.8572\n\tAverage SILog  = 51.3739\nNYU Depth V2 dataset:\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:38<00:00,  2.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"\tAverage AbsRel = 0.1659\n\tAverage Delta1 = 0.7953\n\tAverage SILog  = 83.3935\n====================[ DAV2-Large ]====================\n\n====================[ DAV2-Indoor-Metric ]====================\nIBims-1 dataset:\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:37<00:00,  2.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"\tAverage AbsRel = 0.1265\n\tAverage Delta1 = 0.8861\n\tAverage SILog  = 7.5893\nNYU Depth V2 dataset:\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:35<00:00,  2.84it/s]","output_type":"stream"},{"name":"stdout","text":"\tAverage AbsRel = 0.2250\n\tAverage Delta1 = 0.6607\n\tAverage SILog  = 20.1663\n====================[ DAV2-Indoor-Metric ]====================\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"configs[0].get_absrel_result(\"ibims\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T16:15:56.555931Z","iopub.execute_input":"2026-01-09T16:15:56.556592Z","iopub.status.idle":"2026-01-09T16:15:56.561195Z","shell.execute_reply.started":"2026-01-09T16:15:56.556558Z","shell.execute_reply":"2026-01-09T16:15:56.560644Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"np.float64(0.1252612876460376)"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"name_map = {\n    \"DAV2-Large\": \"depth-anything/Depth-Anything-V2-Large-hf\",\n    \"DAV2-Indoor-Metric\": \"depth-anything/Depth-Anything-V2-Metric-Indoor-Large-hf\",\n    \"ZoeDepth\": \"Intel/zoedepth-nyu-kitti\",\n    \"MiDaS-3.0\": \"Intel/dpt-large\",\n    \"MiDaS-3.1\": \"Intel/dpt-beit-large-512\",\n    \"Marigold-1.1\": \"prs-eth/marigold-depth-v1-1\"\n}\n\n# model : [display_name, relative, ibims, nyu]\nconfigurations = {\n    \"depth-anything/Depth-Anything-V2-Large-hf\": [\"DAV2-Large\", True, True, True],\n    \"depth-anything/Depth-Anything-V2-Metric-Indoor-Large-hf\": [\"DAV2-Indoor-Metric\", False, True, True],\n    \"Intel/zoedepth-nyu-kitti\": [\"ZoeDepth\", False, True, True],\n    \"Intel/dpt-large\": [\"MiDaS-3.0\", True, True, True], # MiDaS 3.0\n    \"Intel/dpt-beit-large-512\": [True, True, True], # MiDaS 3.1\n    \"prs-eth/marigold-depth-v1-1\": [True, True, True]\n}\n\nresults = {}\n\nfor model in configurations.keys():\n    config = configurations[model]\n    relative = config[0]\n    print(f\"{'='*20}[ {model} ]{'='*20}\\n\")\n    if config[1]:\n        print(\"IBims-1 dataset:\")\n        benchmark(ModelWrapper(model), ibims, relative=relative)\n    if config[2]:\n        print(\"NYU Depth V2 dataset:\")\n        benchmark(ModelWrapper(model), nyu, relative=relative)\n    print(f\"{'='*20}[ {model} ]{'='*20}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T14:07:03.071973Z","iopub.execute_input":"2026-01-09T14:07:03.072827Z","iopub.status.idle":"2026-01-09T14:18:20.990566Z","shell.execute_reply.started":"2026-01-09T14:07:03.072791Z","shell.execute_reply":"2026-01-09T14:18:20.989812Z"}},"outputs":[{"name":"stdout","text":"====================[ depth-anything/Depth-Anything-V2-Large-hf ]====================\n\nIBims-1 dataset:\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:38<00:00,  2.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average Abs Rel: 0.1252612876460376\nAverage d_1: 0.8572297850934841\nNYU Depth V2 dataset:\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:36<00:00,  2.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average Abs Rel: 0.1659458577632904\nAverage d_1: 0.7952931966145833\n====================[ depth-anything/Depth-Anything-V2-Large-hf ]====================\n\n====================[ depth-anything/Depth-Anything-V2-Metric-Indoor-Large-hf ]====================\n\nIBims-1 dataset:\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:37<00:00,  2.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average Abs Rel: 0.1264849104849234\nAverage d_1: 0.886137028246952\nNYU Depth V2 dataset:\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:35<00:00,  2.84it/s]","output_type":"stream"},{"name":"stdout","text":"Average Abs Rel: 0.22496400773525238\nAverage d_1: 0.6607259114583335\n====================[ depth-anything/Depth-Anything-V2-Metric-Indoor-Large-hf ]====================\n\n====================[ Intel/zoedepth-nyu-kitti ]====================\n\nIBims-1 dataset:\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/723 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be1be7c6debd4574933d37be6b31ae10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfe537f4afb14e74ae9af08bde22a1ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.38G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a0298f26080493b877e14c89e00ad79"}},"metadata":{}},{"name":"stdout","text":"found zoedepth model\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:30<00:00,  3.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average Abs Rel: 0.20092700231621144\nAverage d_1: 0.6119498442326409\nNYU Depth V2 dataset:\nfound zoedepth model\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:27<00:00,  3.69it/s]","output_type":"stream"},{"name":"stdout","text":"Average Abs Rel: 0.14556682109832764\nAverage d_1: 0.8202607096354169\n====================[ Intel/zoedepth-nyu-kitti ]====================\n\n====================[ Intel/dpt-large ]====================\n\nIBims-1 dataset:\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/285 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"024d9b91796f4c84a8c0d22ab7ba8f20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/942 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c820e0eff2984fdc842e43fe5ef4b15d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.37G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34b45ee737b145e5a076f6ecf9171a84"}},"metadata":{}},{"name":"stderr","text":"Some weights of DPTForDepthEstimation were not initialized from the model checkpoint at Intel/dpt-large and are newly initialized: ['neck.fusion_stage.layers.0.residual_layer1.convolution1.bias', 'neck.fusion_stage.layers.0.residual_layer1.convolution1.weight', 'neck.fusion_stage.layers.0.residual_layer1.convolution2.bias', 'neck.fusion_stage.layers.0.residual_layer1.convolution2.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n100%|██████████| 100/100 [00:16<00:00,  5.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average Abs Rel: 0.13541643258733274\nAverage d_1: 0.8394842777713843\nNYU Depth V2 dataset:\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DPTForDepthEstimation were not initialized from the model checkpoint at Intel/dpt-large and are newly initialized: ['neck.fusion_stage.layers.0.residual_layer1.convolution1.bias', 'neck.fusion_stage.layers.0.residual_layer1.convolution1.weight', 'neck.fusion_stage.layers.0.residual_layer1.convolution2.bias', 'neck.fusion_stage.layers.0.residual_layer1.convolution2.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n100%|██████████| 100/100 [00:14<00:00,  6.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average Abs Rel: 0.1611204892396927\nAverage d_1: 0.7898171223958331\n====================[ Intel/dpt-large ]====================\n\n====================[ Intel/dpt-beit-large-512 ]====================\n\nIBims-1 dataset:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/426 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70fba930defe47c08266363a3261f33f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8af7c4518c774ab98f07e12e625549a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.38G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a4e2a43cda146748f7e5f38f501fd58"}},"metadata":{}},{"name":"stderr","text":"100%|██████████| 100/100 [00:43<00:00,  2.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average Abs Rel: 0.12628050729642812\nAverage d_1: 0.8533818513122847\nNYU Depth V2 dataset:\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:40<00:00,  2.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average Abs Rel: 0.137671560049057\nAverage d_1: 0.8435399739583335\n====================[ Intel/dpt-beit-large-512 ]====================\n\n====================[ prs-eth/marigold-depth-v1-1 ]====================\n\nIBims-1 dataset:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model_index.json:   0%|          | 0.00/534 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8a1869e14ac4a37b88be2e73010de90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3505cbc4f86e4c3f92ada8d98397249d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/633 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"938d15a6c5ea4c5f9e2ce6753ffd85b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scheduler_config.json:   0%|          | 0.00/533 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58ebc5c14a6d4abbb17c1cbe468154c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00e2e634513e4c31bffc373106ea5857"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d5feba864314021be34104a20323b64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/824 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c1ab35882f3433dad4c696038413fe9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02f1303b689e4ee98f67a2861ce2a3ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3255fe134f974d63aa8d82d593ddb497"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"unet/diffusion_pytorch_model.fp16.safete(…):   0%|          | 0.00/1.73G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3df759a27eba4b539cabc005c2882b3b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/611 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd37e15e2eec4a8d86aa878c30e998b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"text_encoder/model.fp16.safetensors:   0%|          | 0.00/681M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d4e5bbe8090421d9259cb5430951d24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vae/diffusion_pytorch_model.fp16.safeten(…):   0%|          | 0.00/167M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58a2295385b841cebfd3ab01ba706c47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0970335e3d7b4be28d0868d523b2d725"}},"metadata":{}},{"name":"stdout","text":"found marigold model\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [02:40<00:00,  1.61s/it]\n","output_type":"stream"},{"name":"stdout","text":"Average Abs Rel: 0.05358334528379531\nAverage d_1: 0.9676189089772491\nNYU Depth V2 dataset:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"836011653cd44bffa969db7867d6ae82"}},"metadata":{}},{"name":"stdout","text":"found marigold model\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [02:38<00:00,  1.59s/it]","output_type":"stream"},{"name":"stdout","text":"Average Abs Rel: 0.09601327776908875\nAverage d_1: 0.8955147786458332\n====================[ prs-eth/marigold-depth-v1-1 ]====================\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":22}]}